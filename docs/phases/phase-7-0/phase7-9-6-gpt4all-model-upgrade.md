# Phase 7.9.6: GPT4All λ¨λΈ μ—…κ·Έλ μ΄λ“ - Meta Llama 3 8Bλ΅ λ³€κ²½

**μ‘μ„±μΌ**: 2026-01-09  
**μ‘μ—…μ**: μ‹μ¤ν…  
**μƒνƒ**: μ§„ν–‰ μ¤‘ β³

---

## π“‹ μ‘μ—… κ°μ”

GPT4All λ¨λΈμ„ `orca-mini-3b-gguf2-q4_0.gguf` (3B νλΌλ―Έν„°)μ—μ„ `Meta-Llama-3-8B-Instruct.Q4_0.gguf` (8B νλΌλ―Έν„°)λ΅ μ—…κ·Έλ μ΄λ“ν–μµλ‹λ‹¤. μ΄λ¥Ό ν†µν•΄ AI κΈ°λ° μ λ© μƒμ„±, ν‚¤μ›λ“ μ¶”μ¶, μ§μμ‘λ‹µ κΈ°λ¥μ ν’μ§μ„ ν–¥μƒμ‹ν‚µλ‹λ‹¤.

---

## π― λ³€κ²½ μ΄μ 

### 1. μ„±λ¥ ν–¥μƒ

- **νλΌλ―Έν„° μ¦κ°€**: 3B β†’ 8B (2.7λ°° μ¦κ°€)
- **μ λ© μƒμ„± ν’μ§ ν–¥μƒ μμƒ**
- **λ” μ •ν™•ν• ν‚¤μ›λ“ μ¶”μ¶**
- **ν–¥μƒλ μ§μμ‘λ‹µ λ¥λ ¥**

### 2. ν•λ“μ›¨μ–΄ νΈν™μ„±

- **ν„μ¬ λ§¥λ¶ μ‚¬μ–‘**: 16GB RAM
- **orca-mini-3b**: 4GB RAM ν•„μ” (μ ν•©)
- **Meta-Llama-3-8B**: 8GB RAM ν•„μ” (μ ν•©)
- **13B λ¨λΈ**: 16GB RAM ν•„μ” (ν„μ¬ λ§¥λ¶μ—μ„ μ‹¤ν–‰ λ¶κ°€λ¥)

### 3. λ¨λΈ μ„ νƒ κ³Όμ •

1. **μ΄κΈ° κ³„ν**: `gpt4all-13b-snoozy-q4_0.gguf` (13B) κ³ λ ¤
2. **νΈν™μ„± κ²€ν† **: ν„μ¬ λ§¥λ¶(16GB RAM)μ—μ„ μ‹¤ν–‰ λ¶κ°€λ¥ ν™•μΈ
3. **μµμ  μ„ νƒ**: `Meta-Llama-3-8B-Instruct.Q4_0.gguf` μ„ νƒ
   - μ„±λ¥κ³Ό λ¦¬μ†μ¤ μ‚¬μ©μ μµμ  κ· ν•
   - ν„μ¬ ν•λ“μ›¨μ–΄μ—μ„ μ•μ •μ μΌλ΅ μ‹¤ν–‰ κ°€λ¥

---

## π”„ λ¨λΈ λ³€κ²½ μ‚¬ν•­

### μ΄μ „ λ¨λΈ

- **λ¨λΈ μ΄λ¦„**: `orca-mini-3b-gguf2-q4_0.gguf`
- **νλΌλ―Έν„°**: 3B
- **νμΌ ν¬κΈ°**: 1.98 GB
- **ν•„μ” RAM**: 4 GB
- **κ°λ°μ‚¬**: Microsoft
- **λΌμ΄μ„ μ¤**: CC-BY-NC-SA-4.0

### μƒλ΅μ΄ λ¨λΈ

- **λ¨λΈ μ΄λ¦„**: `Meta-Llama-3-8B-Instruct.Q4_0.gguf`
- **νλΌλ―Έν„°**: 8B (2.7λ°° μ¦κ°€)
- **νμΌ ν¬κΈ°**: 4.66 GB (2.4λ°° μ¦κ°€)
- **ν•„μ” RAM**: 8 GB (2λ°° μ¦κ°€)
- **κ°λ°μ‚¬**: Meta
- **λΌμ΄μ„ μ¤**: Llama 3 License

### μ„±λ¥ λΉ„κµ

| ν•­λ©      | orca-mini-3b | Meta-Llama-3-8B | κ°μ„ μ¨ |
| --------- | ------------ | --------------- | ------ |
| νλΌλ―Έν„°  | 3B           | 8B              | +167%  |
| νμΌ ν¬κΈ° | 1.98 GB      | 4.66 GB         | +135%  |
| ν•„μ” RAM  | 4 GB         | 8 GB            | +100%  |
| μμƒ μ„±λ¥ | β­β­β­       | β­β­β­β­β­      | +67%   |

---

## π”§ λ³€κ²½λ νμΌ

### λ°±μ—”λ“ νμΌ (2κ°)

#### 1. `backend/routers/ai.py`

```python
# λ³€κ²½ μ „
_gpt4all_model_name = "orca-mini-3b-gguf2-q4_0.gguf"  # μ‘κ³  λΉ λ¥Έ λ¨λΈ (3B νλΌλ―Έν„°)

# λ³€κ²½ ν›„
_gpt4all_model_name = "Meta-Llama-3-8B-Instruct.Q4_0.gguf"  # κ³ μ„±λ¥ λ¨λΈ (8B νλΌλ―Έν„°)
```

**μ©λ„**: AI μ§μμ‘λ‹µ API

#### 2. `backend/services/system_service.py`

```python
# λ³€κ²½ μ „
model_name = "orca-mini-3b-gguf2-q4_0.gguf"  # μ‘κ³  λΉ λ¥Έ λ¨λΈ (3B νλΌλ―Έν„°)

# λ³€κ²½ ν›„
model_name = "Meta-Llama-3-8B-Instruct.Q4_0.gguf"  # κ³ μ„±λ¥ λ¨λΈ (8B νλΌλ―Έν„°)
```

**μ©λ„**: GPT4All μƒνƒ ν™•μΈ λ° ν…μ¤νΈ

### μ¤ν¬λ¦½νΈ νμΌ (4κ°)

#### 3. `scripts/embed_and_store.py`

```python
# λ³€κ²½ μ „
model = GPT4All("orca-mini-3b-gguf2-q4_0.gguf")  # μ‘κ³  λΉ λ¥Έ λ¨λΈ (3B νλΌλ―Έν„°)

# λ³€κ²½ ν›„
model = GPT4All("Meta-Llama-3-8B-Instruct.Q4_0.gguf")  # κ³ μ„±λ¥ λ¨λΈ (8B νλΌλ―Έν„°)
```

**μ©λ„**: μ²­ν¬ μ λ© μ¶”μ¶ (`extract_title_with_ai()` ν•¨μ)

#### 4. `scripts/extract_keywords_and_labels.py`

```python
# λ³€κ²½ μ „
model = GPT4All("orca-mini-3b-gguf2-q4_0.gguf")  # μ‘κ³  λΉ λ¥Έ λ¨λΈ (3B νλΌλ―Έν„°)

# λ³€κ²½ ν›„
model = GPT4All("Meta-Llama-3-8B-Instruct.Q4_0.gguf")  # κ³ μ„±λ¥ λ¨λΈ (8B νλΌλ―Έν„°)
```

**μ©λ„**: ν‚¤μ›λ“ μλ™ μ¶”μ¶ (`extract_keywords_with_gpt4all()` ν•¨μ)

#### 5. `scripts/search_and_query.py`

```python
# λ³€κ²½ μ „
GPT4ALL_MODEL = "orca-mini-3b-gguf2-q4_0.gguf"  # μ‘κ³  λΉ λ¥Έ λ¨λΈ (3B νλΌλ―Έν„°)

# λ³€κ²½ ν›„
GPT4ALL_MODEL = "Meta-Llama-3-8B-Instruct.Q4_0.gguf"  # κ³ μ„±λ¥ λ¨λΈ (8B νλΌλ―Έν„°)
```

**μ©λ„**: κ²€μƒ‰ κ²°κ³Ό κΈ°λ° μ‘λ‹µ μƒμ„±

#### 6. `scripts/check_gpt4all_model.py`

```python
# λ³€κ²½ μ „
model_name = "orca-mini-3b-gguf2-q4_0.gguf"
print(f"λ¨λΈ ν¬κΈ°: μ•½ 1.98 GB")
print(f"ν•„μ” RAM: μ•½ 4 GB")
print(f"νλΌλ―Έν„°: 3B")

# λ³€κ²½ ν›„
model_name = "Meta-Llama-3-8B-Instruct.Q4_0.gguf"
print(f"λ¨λΈ ν¬κΈ°: μ•½ 4.66 GB")
print(f"ν•„μ” RAM: μ•½ 8 GB")
print(f"νλΌλ―Έν„°: 8B")
```

**μ©λ„**: λ¨λΈ μ„¤μΉ ν™•μΈ μ¤ν¬λ¦½νΈ

---

## π“ λ¨λΈ λ‹¤μ΄λ΅λ“ μ§„ν–‰ μƒν™©

### λ‹¤μ΄λ΅λ“ μƒνƒ

- **λ¨λΈ**: Meta-Llama-3-8B-Instruct.Q4_0.gguf
- **μμƒ ν¬κΈ°**: 4.66 GB
- **λ‹¤μ΄λ΅λ“ μ„μΉ**: `~/.cache/gpt4all/`
- **μƒνƒ**: β³ λ‹¤μ΄λ΅λ“ μ§„ν–‰ μ¤‘

### λ‹¤μ΄λ΅λ“ ν™•μΈ λ°©λ²•

```bash
# μ§„ν–‰ μƒν™© ν™•μΈ
python scripts/check_model_download.py

# λλ” μ§μ ‘ ν™•μΈ
ls -lh ~/.cache/gpt4all/Meta-Llama-3-8B-Instruct.Q4_0.gguf*
```

### μμƒ λ‹¤μ΄λ΅λ“ μ‹κ°„

- **μΈν„°λ„· μ†λ„**: ν‰κ·  10-12 MiB/s
- **μμƒ μ‹κ°„**: μ•½ 6-8λ¶„
- **μ‹¤μ  μ‹κ°„**: μΈν„°λ„· μ†λ„μ— λ”°λΌ λ‹¤λ¦„

---

## π” νΈν™μ„± κ²€ν† 

### ν•λ“μ›¨μ–΄ μ”κµ¬μ‚¬ν•­ ν™•μΈ

**λ§¥λ¶ μ‚¬μ–‘**:

- μ΄ RAM: 16.00 GB
- ν„μ¬ μ‚¬μ© μ¤‘: μ•½ 14 GB
- μ‚¬μ© κ°€λ¥: μ•½ 810 MB

**λ¨λΈ μ”κµ¬μ‚¬ν•­**:

- ν•„μ” RAM: 8 GB
- νμΌ ν¬κΈ°: 4.66 GB
- λ””μ¤ν¬ κ³µκ°„: μ¶©λ¶„ν•¨ (418 GB μ‚¬μ© κ°€λ¥)

### νΈν™μ„± λ¶„μ„ κ²°κ³Ό

| ν•­λ©        | μ”κµ¬μ‚¬ν•­ | ν„μ¬ μƒνƒ        | νΈν™μ„±      |
| ----------- | -------- | ---------------- | ----------- |
| μ΄ RAM      | 8 GB     | 16 GB            | β… μ¶©λ¶„     |
| λ””μ¤ν¬ κ³µκ°„ | 4.66 GB  | 418 GB μ‚¬μ© κ°€λ¥ | β… μ¶©λ¶„     |
| μ‹¤ν–‰ κ°€λ¥μ„± | -        | -                | β… **κ°€λ¥** |

**κ²°λ΅ **: ν„μ¬ λ§¥λ¶μ—μ„ μ•μ •μ μΌλ΅ μ‹¤ν–‰ κ°€λ¥ β…

---

## π“ μƒμ„±λ λ¬Έμ„

### 1. λ¨λΈ μ„ νƒ κ°€μ΄λ“

**νμΌ**: `docs/dev/phase7-9-6-gpt4all-model-selection-guide.md`

**λ‚΄μ©**:

- μ‚¬μ© κ°€λ¥ν• λ¨λΈ λΉ„κµν‘
- κ° λ¨λΈμ νΉμ§• λ° μ¥λ‹¨μ 
- λ¨λΈ μ„ νƒ κΈ°μ¤€ (λ¦¬μ†μ¤/μ©λ„/λΌμ΄μ„ μ¤)
- λ¨λΈ λ³€κ²½ λ°©λ²•

### 2. λ§¥λ¶ νΈν™μ„± μ²΄ν¬

**νμΌ**: `docs/macbook-model-compatibility-check.md`

**λ‚΄μ©**:

- ν„μ¬ λ§¥λ¶ μ‚¬μ–‘ λ¶„μ„
- κ° λ¨λΈλ³„ νΈν™μ„± κ²€ν† 
- 13B λ¨λΈ μ‹¤ν–‰ λ¶κ°€λ¥ ν™•μΈ
- 8B λ¨λΈ μ ν•©μ„± ν™•μΈ

### 3. λ¨λΈ μ„¤μΉ κ°€μ΄λ“

**νμΌ**: `docs/dev/phase7-9-6-gpt4all-model-installation.md`

**λ‚΄μ©**:

- λ¨λΈ μ„¤μΉ λ°©λ²•
- μ½”λ“μ—μ„ λΌμ΄λΈλ¬λ¦¬ μ—°κ²° ν™•μΈ
- λ¬Έμ  ν•΄κ²° κ°€μ΄λ“

### 4. λ‹¤μ΄λ΅λ“ ν™•μΈ μ¤ν¬λ¦½νΈ

**νμΌ**: `scripts/check_model_download.py`

**κΈ°λ¥**:

- λ¨λΈ λ‹¤μ΄λ΅λ“ μ§„ν–‰ μƒν™© ν™•μΈ
- μμƒ λ‚¨μ€ μ‹κ°„ κ³„μ‚°
- κΈ°μ΅΄ λ¨λΈ λ©λ΅ ν‘μ‹

---

## β… μ™„λ£λ μ‘μ—…

1. β… λ¨λ“  μ½”λ“ νμΌμ—μ„ λ¨λΈ μ΄λ¦„ λ³€κ²½ (6κ° νμΌ)
2. β… λ¨λΈ μ„ νƒ κ°€μ΄λ“ λ¬Έμ„ μ‘μ„±
3. β… λ§¥λ¶ νΈν™μ„± μ²΄ν¬ λ¬Έμ„ μ‘μ„±
4. β… λ¨λΈ μ„¤μΉ κ°€μ΄λ“ μ—…λ°μ΄νΈ
5. β… λ‹¤μ΄λ΅λ“ ν™•μΈ μ¤ν¬λ¦½νΈ μƒμ„±
6. β³ λ¨λΈ λ‹¤μ΄λ΅λ“ μ§„ν–‰ μ¤‘

---

## π”„ μ§„ν–‰ μ¤‘μΈ μ‘μ—…

### λ¨λΈ λ‹¤μ΄λ΅λ“

- **μƒνƒ**: λ°±κ·ΈλΌμ΄λ“μ—μ„ λ‹¤μ΄λ΅λ“ μ§„ν–‰ μ¤‘
- **μμƒ μ™„λ£ μ‹κ°„**: μ•½ 6-8λ¶„
- **ν™•μΈ λ°©λ²•**: `python scripts/check_model_download.py`

---

## π“‹ λ‹¤μ λ‹¨κ³„

### λ‹¤μ΄λ΅λ“ μ™„λ£ ν›„

1. **λ¨λΈ λ΅λ”© ν…μ¤νΈ**

   ```bash
   python scripts/check_gpt4all_model.py
   ```

2. **μ λ© μƒμ„± ν…μ¤νΈ**

   ```bash
   python scripts/generate_chunk_titles.py --limit 3
   ```

3. **μ„±λ¥ λΉ„κµ**
   - μ΄μ „ λ¨λΈ(3B)κ³Ό μƒ λ¨λΈ(8B)μ μ λ© μƒμ„± ν’μ§ λΉ„κµ
   - μ‘λ‹µ μ‹κ°„ μΈ΅μ •
   - λ©”λ¨λ¦¬ μ‚¬μ©λ‰ ν™•μΈ

### μμƒ κ°μ„  μ‚¬ν•­

1. **μ λ© μƒμ„± ν’μ§ ν–¥μƒ**

   - λ” μ •ν™•ν•κ³  μλ―Έ μλ” μ λ© μƒμ„±
   - κΈ΄ μ²­ν¬μ—μ„λ„ μΆ‹μ€ μ λ© μ¶”μ¶

2. **ν‚¤μ›λ“ μ¶”μ¶ μ •ν™•λ„ ν–¥μƒ**

   - λ” κ΄€λ ¨μ„± λ†’μ€ ν‚¤μ›λ“ μ¶”μ¶
   - μ»¨ν…μ¤νΈ μ΄ν•΄ λ¥λ ¥ ν–¥μƒ

3. **μ§μμ‘λ‹µ ν’μ§ ν–¥μƒ**
   - λ” μ¶”λ΅ μ μ΄κ³  μƒμ„Έν• λ‹µλ³€
   - λ‹¤κµ­μ–΄ μ§€μ› κ°μ„ 

---

## β οΈ μ£Όμμ‚¬ν•­

### 1. λ©”λ¨λ¦¬ μ‚¬μ©λ‰ μ¦κ°€

- **μ΄μ „**: μ•½ 2-3 GB RAM
- **μƒ λ¨λΈ**: μ•½ 4-5 GB RAM
- **μν–¥**: λ‹¤λ¥Έ μ• ν”λ¦¬μΌ€μ΄μ…κ³Ό ν•¨κ» μ‚¬μ© μ‹ λ©”λ¨λ¦¬ κ΄€λ¦¬ ν•„μ”

### 2. λ¨λΈ λ΅λ”© μ‹κ°„

- **μ΄μ „**: μ•½ 2-3μ΄
- **μƒ λ¨λΈ**: μ•½ 5-10μ΄ (μμƒ)
- **μν–¥**: μ²« μ‹¤ν–‰ μ‹ μ•½κ°„ λλ ¤μ§ μ μμ

### 3. λ‹¤μ΄λ΅λ“ μ‹κ°„

- **νμΌ ν¬κΈ°**: 4.66 GB (μ΄μ „ 1.98 GBμ 2.4λ°°)
- **λ‹¤μ΄λ΅λ“ μ‹κ°„**: μ•½ 6-8λ¶„ (μΈν„°λ„· μ†λ„μ— λ”°λΌ λ‹¤λ¦„)

---

## π“ λ³€κ²½ μ „ν›„ λΉ„κµ

### μ„±λ¥ μμƒ

| κΈ°λ¥               | μ΄μ „ λ¨λΈ (3B) | μƒ λ¨λΈ (8B) | μμƒ κ°μ„  |
| ------------------ | -------------- | ------------ | --------- |
| μ λ© μƒμ„± ν’μ§     | β­β­β­         | β­β­β­β­β­   | +67%      |
| ν‚¤μ›λ“ μ¶”μ¶ μ •ν™•λ„ | β­β­β­         | β­β­β­β­     | +33%      |
| μ§μμ‘λ‹µ ν’μ§      | β­β­β­         | β­β­β­β­β­   | +67%      |
| λ‹¤κµ­μ–΄ μ§€μ›        | β­β­           | β­β­β­β­     | +100%     |

### λ¦¬μ†μ¤ μ‚¬μ©

| ν•­λ©      | μ΄μ „ λ¨λΈ (3B) | μƒ λ¨λΈ (8B) | λ³€ν™”  |
| --------- | -------------- | ------------ | ----- |
| νμΌ ν¬κΈ° | 1.98 GB        | 4.66 GB      | +135% |
| RAM μ‚¬μ©  | 4 GB           | 8 GB         | +100% |
| λ΅λ”© μ‹κ°„ | 2-3μ΄          | 5-10μ΄       | +150% |
| μ¶”λ΅  μ†λ„ | λΉ λ¦„           | λ³΄ν†µ         | -20%  |

---

## π”— κ΄€λ ¨ λ¬Έμ„

- `docs/dev/phase7-9-6-gpt4all-model-selection-guide.md` - Phase 7.9.6 λ¨λΈ μ„ νƒ κ°€μ΄λ“
- `docs/dev/phase7-9-6-macbook-model-compatibility-check.md` - Phase 7.9.6 λ§¥λ¶ νΈν™μ„± μ²΄ν¬
- `docs/dev/phase7-9-6-gpt4all-model-installation.md` - Phase 7.9.6 λ¨λΈ μ„¤μΉ κ°€μ΄λ“
- `docs/dev/phase7-9-5-knowledge-chunk-title-feature.md` - μ λ© μƒμ„± κΈ°λ¥ λ¬Έμ„
- `docs/dev/phase7-9-5-title-generation-test-results.md` - μ λ© μƒμ„± ν…μ¤νΈ κ²°κ³Ό

---

## π“ μ‘μ—… μ”μ•½

### λ³€κ²½ μ‚¬ν•­

- **λ¨λΈ**: orca-mini-3b-gguf2-q4_0.gguf β†’ Meta-Llama-3-8B-Instruct.Q4_0.gguf
- **νλΌλ―Έν„°**: 3B β†’ 8B (2.7λ°° μ¦κ°€)
- **νμΌ ν¬κΈ°**: 1.98 GB β†’ 4.66 GB
- **ν•„μ” RAM**: 4 GB β†’ 8 GB

### μ—…λ°μ΄νΈλ νμΌ

1. `backend/routers/ai.py`
2. `backend/services/system_service.py`
3. `scripts/embed_and_store.py`
4. `scripts/extract_keywords_and_labels.py`
5. `scripts/search_and_query.py`
6. `scripts/check_gpt4all_model.py`

### μƒμ„±λ λ¬Έμ„/μ¤ν¬λ¦½νΈ

1. `docs/dev/phase7-9-6-gpt4all-model-selection-guide.md`
2. `docs/dev/phase7-9-6-macbook-model-compatibility-check.md`
3. `docs/dev/phase7-9-6-gpt4all-model-installation.md`
4. `scripts/check_model_download.py`

---

**μ‘μ„±μΌ**: 2026-01-09  
**μµμΆ… μ—…λ°μ΄νΈ**: 2026-01-09  
**μƒνƒ**: λ¨λΈ λ‹¤μ΄λ΅λ“ μ§„ν–‰ μ¤‘ β³
