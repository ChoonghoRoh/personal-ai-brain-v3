#!/usr/bin/env python3
"""
íŒŒì¼ ë³€ê²½ ê°ì§€ ë° ìë™ ì„ë² ë”© ê°±ì‹  ì‹œìŠ¤í…œ
"""

import time
import json
from pathlib import Path
from typing import Dict, Set
from datetime import datetime
import hashlib

from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler, FileModifiedEvent, FileCreatedEvent, FileDeletedEvent

# embed_and_store ëª¨ë“ˆì˜ í•¨ìˆ˜ë“¤ import
import sys
sys.path.insert(0, str(Path(__file__).resolve().parent.parent.parent))

# ì‘ì—… ë¡œê·¸ ì‹œìŠ¤í…œ import
try:
    from work_logger import log_action
    LOGGING_AVAILABLE = True
except ImportError:
    LOGGING_AVAILABLE = False

from embed_and_store import (
    PROJECT_ROOT, BRAIN_DIR, QDRANT_HOST, QDRANT_PORT, 
    COLLECTION_NAME, EMBEDDING_MODEL,
    read_markdown_file, split_text, get_file_hash,
    create_collection_if_not_exists
)
from qdrant_client import QdrantClient
from qdrant_client.models import PointStruct
from sentence_transformers import SentenceTransformer

# íŒŒì¼ í•´ì‹œ ì €ì¥ì†Œ (ë³€ê²½ ê°ì§€ìš©)
HASH_STORE_FILE = PROJECT_ROOT / ".file_hashes.json"


class BrainFileHandler(FileSystemEventHandler):
    """brain ë””ë ‰í† ë¦¬ì˜ íŒŒì¼ ë³€ê²½ì„ ì²˜ë¦¬í•˜ëŠ” í•¸ë“¤ëŸ¬"""
    
    def __init__(self):
        self.qdrant_client = None
        self.embedding_model = None
        self.vector_size = None
        self.file_hashes = self.load_file_hashes()
        self.pending_files: Set[Path] = set()
        self.last_process_time = 0
        self.process_delay = 2  # íŒŒì¼ ë³€ê²½ í›„ 2ì´ˆ ëŒ€ê¸° í›„ ì²˜ë¦¬
        
    def load_file_hashes(self) -> Dict[str, str]:
        """ì €ì¥ëœ íŒŒì¼ í•´ì‹œ ë¡œë“œ"""
        if HASH_STORE_FILE.exists():
            try:
                with open(HASH_STORE_FILE, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                return {}
        return {}
    
    def save_file_hashes(self):
        """íŒŒì¼ í•´ì‹œ ì €ì¥"""
        with open(HASH_STORE_FILE, 'w', encoding='utf-8') as f:
            json.dump(self.file_hashes, f, indent=2, ensure_ascii=False)
    
    def init_models(self):
        """Qdrant í´ë¼ì´ì–¸íŠ¸ ë° ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”"""
        if self.qdrant_client is None:
            self.qdrant_client = QdrantClient(host=QDRANT_HOST, port=QDRANT_PORT)
        
        if self.embedding_model is None:
            print("[ì´ˆê¸°í™”] ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘...")
            self.embedding_model = SentenceTransformer(EMBEDDING_MODEL)
            self.vector_size = self.embedding_model.get_sentence_embedding_dimension()
            create_collection_if_not_exists(self.qdrant_client, COLLECTION_NAME, self.vector_size)
            print("[ì´ˆê¸°í™”] ì™„ë£Œ")
    
    def is_markdown_file(self, file_path: Path) -> bool:
        """Markdown íŒŒì¼ì¸ì§€ í™•ì¸"""
        return file_path.suffix.lower() == '.md' and file_path.is_file()
    
    def is_brain_file(self, file_path: Path) -> bool:
        """brain ë””ë ‰í† ë¦¬ ë‚´ íŒŒì¼ì¸ì§€ í™•ì¸"""
        try:
            relative = file_path.relative_to(PROJECT_ROOT)
            return str(relative).startswith('brain/')
        except ValueError:
            return False
    
    def file_changed(self, file_path: Path) -> bool:
        """íŒŒì¼ì´ ë³€ê²½ë˜ì—ˆëŠ”ì§€ í™•ì¸"""
        if not self.is_markdown_file(file_path) or not self.is_brain_file(file_path):
            return False
        
        current_hash = get_file_hash(file_path)
        relative_path = str(file_path.relative_to(PROJECT_ROOT))
        
        if relative_path not in self.file_hashes:
            # ìƒˆ íŒŒì¼
            self.file_hashes[relative_path] = current_hash
            self.save_file_hashes()
            return True
        
        if self.file_hashes[relative_path] != current_hash:
            # íŒŒì¼ ë³€ê²½ë¨
            self.file_hashes[relative_path] = current_hash
            self.save_file_hashes()
            return True
        
        return False
    
    def process_file(self, file_path: Path):
        """íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ ì„ë² ë”© ìƒì„± ë° ì €ì¥"""
        if not self.is_markdown_file(file_path) or not self.is_brain_file(file_path):
            return
        
        print(f"\n[ì²˜ë¦¬ ì‹œì‘] {file_path.relative_to(PROJECT_ROOT)}")
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self.init_models()
        
        # íŒŒì¼ ì½ê¸°
        content = read_markdown_file(file_path)
        if not content:
            print(f"  âš ï¸  íŒŒì¼ì´ ë¹„ì–´ìˆê±°ë‚˜ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # í…ìŠ¤íŠ¸ ì²­í¬ ë¶„í• 
        chunks = split_text(content)
        if not chunks:
            print(f"  âš ï¸  ì²˜ë¦¬í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        relative_path = str(file_path.relative_to(PROJECT_ROOT))
        
        # ê¸°ì¡´ í¬ì¸íŠ¸ ì‚­ì œ (í•´ë‹¹ íŒŒì¼ì˜ ëª¨ë“  ì²­í¬)
        self.delete_file_points(relative_path)
        
        # ìƒˆ í¬ì¸íŠ¸ ìƒì„± ë° ì €ì¥
        points = []
        for idx, chunk in enumerate(chunks):
            # ì„ë² ë”© ìƒì„±
            embedding = self.embedding_model.encode(chunk).tolist()
            
            # ê³ ìœ  ID ìƒì„±
            point_id = hash(f"{relative_path}_{idx}") % (2**63)
            
            # Qdrant í¬ì¸íŠ¸ ìƒì„±
            point = PointStruct(
                id=point_id,
                vector=embedding,
                payload={
                    'file_path': relative_path,
                    'chunk_index': idx,
                    'content': chunk
                }
            )
            points.append(point)
        
        # ë°°ì¹˜ë¡œ ì €ì¥
        if points:
            self.qdrant_client.upsert(
                collection_name=COLLECTION_NAME,
                points=points
            )
            print(f"  âœ… {len(points)}ê°œì˜ ì²­í¬ ì €ì¥ ì™„ë£Œ")
            
            # ì‘ì—… ë¡œê·¸ ê¸°ë¡
            if LOGGING_AVAILABLE:
                log_action(
                    action="embed",
                    description=f"íŒŒì¼ ì„ë² ë”© ë° ì €ì¥: {relative_path}",
                    files=[relative_path],
                    metadata={
                        'chunks_count': len(points),
                        'file_path': relative_path
                    }
                )
        else:
            print(f"  âš ï¸  ì €ì¥í•  í¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    def delete_file_points(self, file_path: str):
        """íŠ¹ì • íŒŒì¼ì˜ ëª¨ë“  í¬ì¸íŠ¸ ì‚­ì œ"""
        try:
            # íŒŒì¼ ê²½ë¡œë¡œ í•„í„°ë§í•˜ì—¬ ì‚­ì œ
            from qdrant_client.models import Filter, FieldCondition, MatchValue
            
            # ëª¨ë“  í¬ì¸íŠ¸ë¥¼ ìŠ¤í¬ë¡¤í•˜ì—¬ í•´ë‹¹ íŒŒì¼ì˜ í¬ì¸íŠ¸ ì°¾ê¸°
            scroll_result = self.qdrant_client.scroll(
                collection_name=COLLECTION_NAME,
                scroll_filter=Filter(
                    must=[
                        FieldCondition(
                            key="file_path",
                            match=MatchValue(value=file_path)
                        )
                    ]
                ),
                limit=1000
            )
            
            if scroll_result[0]:  # pointsê°€ ìˆìœ¼ë©´
                point_ids = [point.id for point in scroll_result[0]]
                self.qdrant_client.delete(
                    collection_name=COLLECTION_NAME,
                    points_selector=point_ids
                )
                print(f"  ğŸ—‘ï¸  ê¸°ì¡´ {len(point_ids)}ê°œ í¬ì¸íŠ¸ ì‚­ì œ")
        except Exception as e:
            print(f"  âš ï¸  ê¸°ì¡´ í¬ì¸íŠ¸ ì‚­ì œ ì¤‘ ì˜¤ë¥˜: {e}")
    
    def on_modified(self, event):
        """íŒŒì¼ ìˆ˜ì • ì´ë²¤íŠ¸ ì²˜ë¦¬"""
        if not event.is_directory:
            file_path = Path(event.src_path)
            if self.file_changed(file_path):
                self.pending_files.add(file_path)
                self.last_process_time = time.time()
                relative_path = str(file_path.relative_to(PROJECT_ROOT))
                print(f"\n[ë³€ê²½ ê°ì§€] {relative_path}")
                
                # ì‘ì—… ë¡œê·¸ ê¸°ë¡
                if LOGGING_AVAILABLE:
                    log_action(
                        action="file_change",
                        description=f"íŒŒì¼ ë³€ê²½ ê°ì§€: {relative_path}",
                        files=[relative_path],
                        metadata={'event': 'modified'}
                    )
    
    def on_created(self, event):
        """íŒŒì¼ ìƒì„± ì´ë²¤íŠ¸ ì²˜ë¦¬"""
        if not event.is_directory:
            file_path = Path(event.src_path)
            if self.file_changed(file_path):
                self.pending_files.add(file_path)
                self.last_process_time = time.time()
                relative_path = str(file_path.relative_to(PROJECT_ROOT))
                print(f"\n[ìƒˆ íŒŒì¼] {relative_path}")
                
                # ì‘ì—… ë¡œê·¸ ê¸°ë¡
                if LOGGING_AVAILABLE:
                    log_action(
                        action="file_change",
                        description=f"ìƒˆ íŒŒì¼ ìƒì„±: {relative_path}",
                        files=[relative_path],
                        metadata={'event': 'created'}
                    )
    
    def on_deleted(self, event):
        """íŒŒì¼ ì‚­ì œ ì´ë²¤íŠ¸ ì²˜ë¦¬"""
        if not event.is_directory:
            file_path = Path(event.src_path)
            relative_path = str(file_path.relative_to(PROJECT_ROOT))
            
            # í•´ì‹œì—ì„œ ì œê±°
            if relative_path in self.file_hashes:
                del self.file_hashes[relative_path]
                self.save_file_hashes()
            
            # Qdrantì—ì„œ ì‚­ì œ
            self.init_models()
            self.delete_file_points(relative_path)
            print(f"\n[ì‚­ì œ] {relative_path}")
            
            # ì‘ì—… ë¡œê·¸ ê¸°ë¡
            if LOGGING_AVAILABLE:
                log_action(
                    action="file_change",
                    description=f"íŒŒì¼ ì‚­ì œ: {relative_path}",
                    files=[relative_path],
                    metadata={'event': 'deleted'}
                )
    
    def process_pending_files(self):
        """ëŒ€ê¸° ì¤‘ì¸ íŒŒì¼ë“¤ ì²˜ë¦¬"""
        current_time = time.time()
        
        # ë§ˆì§€ë§‰ ë³€ê²½ í›„ ì¼ì • ì‹œê°„ ê²½ê³¼í–ˆëŠ”ì§€ í™•ì¸
        if self.pending_files and (current_time - self.last_process_time) >= self.process_delay:
            files_to_process = list(self.pending_files)
            self.pending_files.clear()
            
            for file_path in files_to_process:
                try:
                    self.process_file(file_path)
                except Exception as e:
                    print(f"  âŒ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")


def watch_brain_directory():
    """brain ë””ë ‰í† ë¦¬ ê°ì‹œ ì‹œì‘"""
    print("=" * 60)
    print("Personal AI Brain - íŒŒì¼ ë³€ê²½ ê°ì§€ ì‹œìŠ¤í…œ ì‹œì‘")
    print("=" * 60)
    print(f"ê°ì‹œ ë””ë ‰í† ë¦¬: {BRAIN_DIR}")
    print(f"Qdrant: {QDRANT_HOST}:{QDRANT_PORT}")
    print(f"ì»¬ë ‰ì…˜: {COLLECTION_NAME}")
    print("\níŒŒì¼ ë³€ê²½ì„ ê°ì§€í•˜ë©´ ìë™ìœ¼ë¡œ ì„ë² ë”©ì„ ê°±ì‹ í•©ë‹ˆë‹¤.")
    print("ì¢…ë£Œí•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”.\n")
    
    event_handler = BrainFileHandler()
    observer = Observer()
    observer.schedule(event_handler, str(BRAIN_DIR), recursive=True)
    observer.start()
    
    try:
        while True:
            time.sleep(0.5)
            event_handler.process_pending_files()
    except KeyboardInterrupt:
        print("\n\n[ì¢…ë£Œ] íŒŒì¼ ê°ì‹œë¥¼ ì¤‘ì§€í•©ë‹ˆë‹¤...")
        observer.stop()
    
    observer.join()
    print("[ì¢…ë£Œ] ì™„ë£Œ")


if __name__ == "__main__":
    watch_brain_directory()

