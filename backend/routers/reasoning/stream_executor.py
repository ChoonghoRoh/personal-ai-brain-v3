"""Reasoning ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰ ì—”ì§„ (reason_stream.pyì—ì„œ ë¶„ë¦¬)

execute_reasoning_with_progress ë° ê´€ë ¨ í—¬í¼ í•¨ìˆ˜ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
"""
import asyncio
import json
import time
import logging
from typing import Dict, List, Optional, AsyncGenerator
from sqlalchemy.orm import Session

from backend.models.models import (
    Project, Document, KnowledgeChunk, Label, KnowledgeLabel, KnowledgeRelation,
)
from backend.services.search.search_service import get_search_service
from backend.services.reasoning.dynamic_reasoning_service import get_dynamic_reasoning_service
from backend.services.reasoning.recommendation_service import get_recommendation_service
from backend.routers.reasoning.reason_helpers import (
    collect_chunks_by_document_ids,
    collect_chunks_by_question_in_documents,
)

logger = logging.getLogger(__name__)

# ì§„í–‰ ì¤‘ì¸ íƒœìŠ¤í¬ ê´€ë¦¬ (ì·¨ì†Œ ê¸°ëŠ¥ìš©)
active_tasks: Dict[str, Dict] = {}

# ì§„í–‰ ë‹¨ê³„ ì •ì˜
PROGRESS_STAGES = [
    {"stage": 1, "message": "ì§ˆë¬¸ ë¶„ì„ ì¤‘...", "percent": 10},
    {"stage": 2, "message": "ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...", "percent": 30},
    {"stage": 3, "message": "ì—°ê´€ ì§€ì‹ í™•ì¥ ì¤‘...", "percent": 50},
    {"stage": 4, "message": "AI ì¶”ë¡  ì¤‘...", "percent": 70},
    {"stage": 5, "message": "ì¶”ì²œ ì •ë³´ ìƒì„± ì¤‘...", "percent": 90},
]


def format_sse_event(event_type: str, data: dict) -> str:
    """SSE í˜•ì‹ìœ¼ë¡œ ì´ë²¤íŠ¸ í¬ë§·íŒ…"""
    return f"event: {event_type}\ndata: {json.dumps(data, ensure_ascii=False)}\n\n"


# ---------------------------------------------------------------------------
# ì§€ì‹ ìˆ˜ì§‘ í—¬í¼ (ìŠ¤íŠ¸ë¦¬ë° ì „ìš© â€” ê°„ì†Œí™” ë²„ì „)
# ---------------------------------------------------------------------------

def collect_knowledge_from_projects(db: Session, project_ids: List[int]) -> List[KnowledgeChunk]:
    """í”„ë¡œì íŠ¸ì—ì„œ ì§€ì‹ ì²­í¬ ìˆ˜ì§‘"""
    chunks = []
    for project_id in project_ids:
        project = db.query(Project).filter(Project.id == project_id).first()
        if not project:
            continue
        documents = db.query(Document).filter(Document.project_id == project_id).all()
        for doc in documents:
            doc_chunks = db.query(KnowledgeChunk).filter(
                KnowledgeChunk.document_id == doc.id,
                KnowledgeChunk.status == "approved"
            ).all()
            chunks.extend(doc_chunks)
    return chunks


def collect_knowledge_from_labels(db: Session, label_names: List[str]) -> List[KnowledgeChunk]:
    """ë¼ë²¨ì—ì„œ ì§€ì‹ ìˆ˜ì§‘"""
    chunks = []
    labels = db.query(Label).filter(Label.name.in_(label_names)).all()
    for label in labels:
        knowledge_labels = db.query(KnowledgeLabel).filter(KnowledgeLabel.label_id == label.id).all()
        for kl in knowledge_labels:
            chunk = db.query(KnowledgeChunk).filter(
                KnowledgeChunk.id == kl.chunk_id,
                KnowledgeChunk.status == "approved"
            ).first()
            if chunk:
                chunks.append(chunk)
    return chunks


def collect_knowledge_from_label_ids(db: Session, label_ids: List[int]) -> List[KnowledgeChunk]:
    """ë¼ë²¨ IDë¡œ ì§€ì‹ ìˆ˜ì§‘"""
    chunks = []
    knowledge_labels = db.query(KnowledgeLabel).filter(
        KnowledgeLabel.label_id.in_(label_ids),
        KnowledgeLabel.status == "confirmed"
    ).all()
    chunk_ids = {kl.chunk_id for kl in knowledge_labels}
    if chunk_ids:
        chunks = db.query(KnowledgeChunk).filter(
            KnowledgeChunk.id.in_(chunk_ids),
            KnowledgeChunk.status == "approved"
        ).all()
    return chunks


def trace_relations(db: Session, chunks: List[KnowledgeChunk], depth: int = 2) -> List[KnowledgeChunk]:
    """ê´€ê³„ë¥¼ ë”°ë¼ ì§€ì‹ ì²­í¬ ì¶”ì """
    all_chunks = {chunk.id: chunk for chunk in chunks}
    current_chunk_ids = [chunk.id for chunk in chunks]

    for _ in range(depth):
        if not current_chunk_ids:
            break
        relations = db.query(KnowledgeRelation).filter(
            (
                (KnowledgeRelation.source_chunk_id.in_(current_chunk_ids)) |
                (KnowledgeRelation.target_chunk_id.in_(current_chunk_ids))
            ),
            KnowledgeRelation.confirmed == "true"
        ).all()

        related_chunk_ids = set()
        for rel in relations:
            if rel.source_chunk_id in current_chunk_ids:
                related_chunk_ids.add(rel.target_chunk_id)
            if rel.target_chunk_id in current_chunk_ids:
                related_chunk_ids.add(rel.source_chunk_id)

        related_chunk_ids = related_chunk_ids - set(all_chunks.keys())
        if not related_chunk_ids:
            break

        next_chunks = db.query(KnowledgeChunk).filter(
            KnowledgeChunk.id.in_(related_chunk_ids),
            KnowledgeChunk.status == "approved"
        ).all()

        for chunk in next_chunks:
            all_chunks[chunk.id] = chunk
        current_chunk_ids = [chunk.id for chunk in next_chunks]

    return list(all_chunks.values())


# ---------------------------------------------------------------------------
# ë¹„ë™ê¸° í† í° ìŠ¤íŠ¸ë¦¬ë°
# ---------------------------------------------------------------------------

async def _async_stream_tokens(sync_gen):
    """ë™ê¸° ì œë„ˆë ˆì´í„°ë¥¼ ë¹„ë™ê¸°ë¡œ ë³€í™˜ (executorì—ì„œ next() í˜¸ì¶œ) -- Phase 10-4-1."""
    loop = asyncio.get_event_loop()
    it = iter(sync_gen)
    while True:
        try:
            token = await loop.run_in_executor(None, next, it)
            yield token
        except StopIteration:
            break


# ---------------------------------------------------------------------------
# ë©”ì¸ ì‹¤í–‰ê¸°
# ---------------------------------------------------------------------------

async def execute_reasoning_with_progress(
    task_id: str,
    request,
    db: Session,
) -> AsyncGenerator[str, None]:
    """ì§„í–‰ ìƒíƒœë¥¼ í¬í•¨í•œ Reasoning ì‹¤í–‰ (ì œë„ˆë ˆì´í„°)"""
    start_time = time.time()
    reasoning_steps = []

    # íƒœìŠ¤í¬ ë“±ë¡
    active_tasks[task_id] = {
        "status": "running",
        "started_at": start_time,
        "cancelled": False,
    }

    try:
        # Stage 1: ì§ˆë¬¸ ë¶„ì„
        yield format_sse_event("progress", {
            "task_id": task_id,
            "stage": 1,
            "total_stages": 5,
            "message": "ì§ˆë¬¸ ë¶„ì„ ì¤‘...",
            "percent": 10,
            "elapsed": round(time.time() - start_time, 1),
        })

        if active_tasks.get(task_id, {}).get("cancelled"):
            yield format_sse_event("cancelled", {"task_id": task_id, "message": "ì‚¬ìš©ìì— ì˜í•´ ì·¨ì†Œë¨"})
            return

        reasoning_steps.append("ì…ë ¥ íŒŒì‹± ì¤‘...")
        project_ids = request.inputs.get("projects", [])
        label_names = request.inputs.get("labels", [])
        filter_label_ids = []

        # Phase 15-3: document_ids íŒŒì‹±
        document_ids = []
        if request.filters:
            if request.filters.category_label_ids:
                filter_label_ids.extend(request.filters.category_label_ids)
            if request.filters.keyword_group_ids:
                filter_label_ids.extend(request.filters.keyword_group_ids)
            if request.filters.keyword_ids:
                filter_label_ids.extend(request.filters.keyword_ids)
            if request.filters.project_ids:
                project_ids = list(set(project_ids + request.filters.project_ids))
            if request.filters.document_ids:
                document_ids = request.filters.document_ids

        question = (request.question or "").strip()
        await asyncio.sleep(0.1)

        # Stage 2: ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        yield format_sse_event("progress", {
            "task_id": task_id,
            "stage": 2,
            "total_stages": 5,
            "message": "ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...",
            "percent": 30,
            "elapsed": round(time.time() - start_time, 1),
        })

        if active_tasks.get(task_id, {}).get("cancelled"):
            yield format_sse_event("cancelled", {"task_id": task_id, "message": "ì‚¬ìš©ìì— ì˜í•´ ì·¨ì†Œë¨"})
            return

        chunks = []

        # Phase 15-3: ë¬¸ì„œ ê¸°ë°˜ ìˆ˜ì§‘ ìš°ì„ 
        if document_ids:
            if question:
                chunks = collect_chunks_by_question_in_documents(
                    db, question, document_ids, top_k=20, reasoning_steps=reasoning_steps
                )
                if len(chunks) < 5:
                    doc_chunks = collect_chunks_by_document_ids(db, document_ids)
                    seen = {c.id for c in chunks}
                    for c in doc_chunks:
                        if c.id not in seen:
                            seen.add(c.id)
                            chunks.append(c)
                    reasoning_steps.append(f"ë¬¸ì„œ ì „ì²´ ì²­í¬ ë³´ê°•: ì´ {len(chunks)}ê°œ")
            else:
                chunks = collect_chunks_by_document_ids(db, document_ids)
                reasoning_steps.append(f"ë¬¸ì„œì—ì„œ {len(chunks)}ê°œ ì²­í¬ ìˆ˜ì§‘")
        elif question:
            reasoning_steps.append("ì§ˆë¬¸ ê¸°ë°˜ ì˜ë¯¸ ê²€ìƒ‰ ì¤‘...")
            search_service = get_search_service()
            search_results = search_service.search_simple(question.strip(), top_k=20, use_cache=False)
            seen = set()
            for result in search_results:
                qdrant_id = result.get("document_id")
                chunk = db.query(KnowledgeChunk).filter(
                    KnowledgeChunk.qdrant_point_id == str(qdrant_id),
                    KnowledgeChunk.status == "approved",
                ).first()
                if chunk and chunk.id not in seen:
                    seen.add(chunk.id)
                    chunks.append(chunk)
            reasoning_steps.append(f"ì˜ë¯¸ ê²€ìƒ‰ìœ¼ë¡œ {len(chunks)}ê°œ ì²­í¬ ìˆ˜ì§‘")

        # ë³´ì¡° í•„í„° ì ìš© (ë¬¸ì„œ í•„í„°ê°€ ì•„ë‹Œ ê²½ìš°)
        if not document_ids:
            if project_ids:
                project_chunks = collect_knowledge_from_projects(db, project_ids)
                seen = {c.id for c in chunks}
                for c in project_chunks:
                    if c.id not in seen:
                        seen.add(c.id)
                        chunks.append(c)
                reasoning_steps.append(f"í”„ë¡œì íŠ¸ì—ì„œ {len(project_chunks)}ê°œ ì²­í¬ ìˆ˜ì§‘")

            if label_names:
                label_chunks = collect_knowledge_from_labels(db, label_names)
                seen = {c.id for c in chunks}
                for c in label_chunks:
                    if c.id not in seen:
                        seen.add(c.id)
                        chunks.append(c)
                reasoning_steps.append(f"ë¼ë²¨ì—ì„œ {len(label_chunks)}ê°œ ì²­í¬ ìˆ˜ì§‘")

            if filter_label_ids:
                filter_chunks = collect_knowledge_from_label_ids(db, filter_label_ids)
                seen = {c.id for c in chunks}
                for c in filter_chunks:
                    if c.id not in seen:
                        seen.add(c.id)
                        chunks.append(c)
                reasoning_steps.append(f"í‚¤ì›Œë“œ í•„í„°ì—ì„œ {len(filter_chunks)}ê°œ ì²­í¬ ìˆ˜ì§‘")

        # ì§ˆë¬¸ ì—†ì´ í•„í„°ë„ ì—†ì„ ë•Œ í´ë°±
        if not chunks and not question and not document_ids:
            fallback = db.query(KnowledgeChunk).filter(
                KnowledgeChunk.status == "approved"
            ).order_by(KnowledgeChunk.id.desc()).limit(100).all()
            if fallback:
                chunks = fallback
                reasoning_steps.append(f"í•„í„° ì—†ìŒ â†’ ìŠ¹ì¸ëœ ì „ì²´ ì²­í¬ {len(fallback)}ê°œ ì‚¬ìš©")

        await asyncio.sleep(0.1)

        # Stage 3: ì—°ê´€ ì§€ì‹ í™•ì¥
        yield format_sse_event("progress", {
            "task_id": task_id,
            "stage": 3,
            "total_stages": 5,
            "message": "ì—°ê´€ ì§€ì‹ í™•ì¥ ì¤‘...",
            "percent": 50,
            "elapsed": round(time.time() - start_time, 1),
        })

        if active_tasks.get(task_id, {}).get("cancelled"):
            yield format_sse_event("cancelled", {"task_id": task_id, "message": "ì‚¬ìš©ìì— ì˜í•´ ì·¨ì†Œë¨"})
            return

        reasoning_steps.append("ê´€ê³„ ì¶”ì  ì¤‘...")
        all_chunks = trace_relations(db, chunks, depth=2)
        reasoning_steps.append(f"ê´€ê³„ë¥¼ í†µí•´ {len(all_chunks) - len(chunks)}ê°œ ì¶”ê°€ ì²­í¬ ë°œê²¬")

        await asyncio.sleep(0.1)

        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        chunks_to_process = all_chunks[:20]
        chunk_ids = [c.id for c in chunks_to_process]

        document_ids = list(set([chunk.document_id for chunk in chunks_to_process]))
        documents = {doc.id: doc for doc in db.query(Document).filter(Document.id.in_(document_ids)).all()}

        project_ids_list = list(set([doc.project_id for doc in documents.values() if doc.project_id]))
        projects = {proj.id: proj for proj in db.query(Project).filter(Project.id.in_(project_ids_list)).all()} if project_ids_list else {}

        chunk_labels: Dict[int, List[str]] = {cid: [] for cid in chunk_ids}
        if chunk_ids:
            knowledge_labels = (
                db.query(KnowledgeLabel.chunk_id, Label.name)
                .join(Label, KnowledgeLabel.label_id == Label.id)
                .filter(
                    KnowledgeLabel.chunk_id.in_(chunk_ids),
                    KnowledgeLabel.status == "confirmed",
                )
                .all()
            )
            for cid, name in knowledge_labels:
                if name and cid in chunk_labels:
                    chunk_labels[cid].append(name)

        context_chunks = []
        for chunk in chunks_to_process:
            doc = documents.get(chunk.document_id)
            project = projects.get(doc.project_id) if doc and doc.project_id else None
            context_chunks.append({
                "id": chunk.id,
                "content": chunk.content[:200] + "..." if len(chunk.content) > 200 else chunk.content,
                "document": doc.file_name if doc else None,
                "project": project.name if project else None,
                "project_id": doc.project_id if doc else None,
                "labels": chunk_labels.get(chunk.id) or [],
            })

        # ê´€ê³„ ì •ë³´ ìˆ˜ì§‘
        relations = []
        if chunks[:10]:
            chunk_ids_for_rel = [chunk.id for chunk in chunks[:10]]
            all_relations = db.query(KnowledgeRelation).filter(
                KnowledgeRelation.source_chunk_id.in_(chunk_ids_for_rel)
            ).all()
            target_chunk_ids = list(set([rel.target_chunk_id for rel in all_relations]))
            target_chunks = {
                chunk.id: chunk
                for chunk in db.query(KnowledgeChunk).filter(KnowledgeChunk.id.in_(target_chunk_ids)).all()
            }
            chunk_dict = {chunk.id: chunk for chunk in chunks[:10]}
            for rel in all_relations:
                source_chunk = chunk_dict.get(rel.source_chunk_id)
                target_chunk = target_chunks.get(rel.target_chunk_id)
                if source_chunk and target_chunk:
                    relations.append({
                        "type": rel.relation_type,
                        "source": source_chunk.content[:50],
                        "target": target_chunk.content[:50],
                        "description": rel.description,
                    })

        # Stage 4: AI ì¶”ë¡ 
        yield format_sse_event("progress", {
            "task_id": task_id,
            "stage": 4,
            "total_stages": 5,
            "message": "AI ì¶”ë¡  ì¤‘...",
            "percent": 70,
            "elapsed": round(time.time() - start_time, 1),
        })

        if active_tasks.get(task_id, {}).get("cancelled"):
            yield format_sse_event("cancelled", {"task_id": task_id, "message": "ì‚¬ìš©ìì— ì˜í•´ ì·¨ì†Œë¨"})
            return

        reasoning_steps.append("Reasoning ì‹¤í–‰ ì¤‘...")
        dynamic_svc = get_dynamic_reasoning_service()

        # Phase 10-4-1: í† í° ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë° ì‹œë„
        answer_parts = []
        try:
            async for token in _async_stream_tokens(
                dynamic_svc.generate_reasoning_stream(
                    request.question, context_chunks, request.mode,
                    max_tokens=500, model=request.model
                )
            ):
                if active_tasks.get(task_id, {}).get("cancelled"):
                    yield format_sse_event("cancelled", {"task_id": task_id, "message": "ì‚¬ìš©ìì— ì˜í•´ ì·¨ì†Œë¨"})
                    return
                answer_parts.append(token)
                yield format_sse_event("answer_token", {"task_id": task_id, "token": token})
        except Exception as e:
            logger.debug("Streaming fallback triggered: %s", e)

        if answer_parts:
            answer = dynamic_svc._postprocess_reasoning("".join(answer_parts))
        else:
            answer = dynamic_svc.generate_reasoning(
                request.question, context_chunks, request.mode, max_tokens=500, model=request.model
            )

        if answer is None:
            mode = request.mode
            if mode == "design_explain":
                answer = f"ğŸ“ ì„¤ê³„/ë°°ê²½ ì„¤ëª…\n\nìˆ˜ì§‘ëœ {len(all_chunks)}ê°œ ì§€ì‹ ì¡°ê°ì„ ê¸°ë°˜ìœ¼ë¡œ ì„¤ê³„ ë°°ê²½ê³¼ ë§¥ë½ì„ ì„¤ëª…í•©ë‹ˆë‹¤."
            elif mode == "risk_review":
                answer = f"âš ï¸ ë¦¬ìŠ¤í¬ ë¶„ì„\n\n{len(all_chunks)}ê°œ ê´€ë ¨ ì§€ì‹ì„ ë¶„ì„í•˜ì—¬ ì ì¬ì  ë¦¬ìŠ¤í¬ë¥¼ ì‹ë³„í•©ë‹ˆë‹¤."
            elif mode == "next_steps":
                answer = f"ğŸš€ ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ\n\n{len(all_chunks)}ê°œ ê´€ë ¨ ì§€ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤."
            else:
                answer = f"ğŸ“œ íˆìŠ¤í† ë¦¬/ë§¥ë½ ì¶”ì \n\n{len(all_chunks)}ê°œ ì§€ì‹ì„ ì‹œê°„ì /ë…¼ë¦¬ì  ìˆœì„œë¡œ ì¶”ì í•©ë‹ˆë‹¤."

        reasoning_steps.append("Reasoning ì™„ë£Œ")

        # Stage 5: ì¶”ì²œ ì •ë³´ ìƒì„±
        yield format_sse_event("progress", {
            "task_id": task_id,
            "stage": 5,
            "total_stages": 5,
            "message": "ì¶”ì²œ ì •ë³´ ìƒì„± ì¤‘...",
            "percent": 90,
            "elapsed": round(time.time() - start_time, 1),
        })

        if active_tasks.get(task_id, {}).get("cancelled"):
            yield format_sse_event("cancelled", {"task_id": task_id, "message": "ì‚¬ìš©ìì— ì˜í•´ ì·¨ì†Œë¨"})
            return

        recommendations = None
        try:
            rec_svc = get_recommendation_service(db)
            context_chunk_ids = [c.get("id") for c in context_chunks if c.get("id")]
            related_chunks = rec_svc.recommend_related_chunks(context_chunk_ids, limit=5) if context_chunk_ids else []
            combined_content = " ".join([(c.get("content") or "")[:300] for c in context_chunks])
            suggested_labels = rec_svc.recommend_labels(combined_content, limit=5) if combined_content.strip() else []
            sample_questions = rec_svc.generate_sample_questions(limit=3, model=request.model)
            explore_more = rec_svc.suggest_exploration(context_chunk_ids=context_chunk_ids, limit=5)
            recommendations = {
                "related_chunks": related_chunks,
                "suggested_labels": suggested_labels,
                "sample_questions": sample_questions,
                "explore_more": explore_more,
            }
        except Exception as e:
            logger.debug("recommendations build failed: %s", e)

        # ì™„ë£Œ
        elapsed_time = round(time.time() - start_time, 1)
        yield format_sse_event("progress", {
            "task_id": task_id,
            "stage": 5,
            "total_stages": 5,
            "message": "ì™„ë£Œ!",
            "percent": 100,
            "elapsed": elapsed_time,
        })

        # ìµœì¢… ê²°ê³¼ ì „ì†¡
        result = {
            "task_id": task_id,
            "answer": answer,
            "context_chunks": context_chunks,
            "relations": relations,
            "reasoning_steps": reasoning_steps,
            "recommendations": recommendations,
            "elapsed_time": elapsed_time,
        }
        yield format_sse_event("result", result)
        yield format_sse_event("done", {"task_id": task_id})

    except Exception as e:
        logger.error("Reasoning error: %s", e)
        yield format_sse_event("error", {
            "task_id": task_id,
            "message": str(e),
        })
    finally:
        if task_id in active_tasks:
            del active_tasks[task_id]
