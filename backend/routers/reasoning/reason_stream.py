"""Reasoning ìŠ¤íŠ¸ë¦¬ë° API ë¼ìš°í„° (Phase 10-1-1, 10-4-1 LLM í† í° ìŠ¤íŠ¸ë¦¬ë°)

SSE(Server-Sent Events)ë¥¼ ì‚¬ìš©í•˜ì—¬ Reasoning ì§„í–‰ ìƒíƒœë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì „ì†¡í•©ë‹ˆë‹¤.

5ë‹¨ê³„ ì§„í–‰ ìƒíƒœ:
1. ì§ˆë¬¸ ë¶„ì„ ì¤‘...
2. ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...
3. ì—°ê´€ ì§€ì‹ í™•ì¥ ì¤‘...
4. AI ì¶”ë¡  ì¤‘... (í† í° ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë°)
5. ì¶”ì²œ ì •ë³´ ìƒì„± ì¤‘...
"""
import asyncio
import json
import uuid
import time
import logging
from typing import Dict, List, Optional, AsyncGenerator
from fastapi import APIRouter, Depends, HTTPException
from fastapi.responses import StreamingResponse
from sqlalchemy.orm import Session
from pydantic import BaseModel

from backend.models.database import get_db
from backend.models.models import Project, Document, KnowledgeChunk, Label, KnowledgeLabel, KnowledgeRelation
from backend.services.search.search_service import get_search_service
from backend.services.reasoning.dynamic_reasoning_service import get_dynamic_reasoning_service
from backend.services.reasoning.recommendation_service import get_recommendation_service

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/reason", tags=["Reasoning Stream"])

# ì§„í–‰ ì¤‘ì¸ íƒœìŠ¤í¬ ê´€ë¦¬ (ì·¨ì†Œ ê¸°ëŠ¥ìš©)
active_tasks: Dict[str, Dict] = {}


class ReasonFilters(BaseModel):
    project_ids: Optional[List[int]] = None
    category_label_ids: Optional[List[int]] = None
    keyword_group_ids: Optional[List[int]] = None
    keyword_ids: Optional[List[int]] = None


class ReasonStreamRequest(BaseModel):
    mode: str = "design_explain"
    inputs: Dict
    question: Optional[str] = None
    filters: Optional[ReasonFilters] = None
    model: Optional[str] = None


# ì§„í–‰ ë‹¨ê³„ ì •ì˜
PROGRESS_STAGES = [
    {"stage": 1, "message": "ì§ˆë¬¸ ë¶„ì„ ì¤‘...", "percent": 10},
    {"stage": 2, "message": "ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...", "percent": 30},
    {"stage": 3, "message": "ì—°ê´€ ì§€ì‹ í™•ì¥ ì¤‘...", "percent": 50},
    {"stage": 4, "message": "AI ì¶”ë¡  ì¤‘...", "percent": 70},
    {"stage": 5, "message": "ì¶”ì²œ ì •ë³´ ìƒì„± ì¤‘...", "percent": 90},
]


def format_sse_event(event_type: str, data: dict) -> str:
    """SSE í˜•ì‹ìœ¼ë¡œ ì´ë²¤íŠ¸ í¬ë§·íŒ…"""
    return f"event: {event_type}\ndata: {json.dumps(data, ensure_ascii=False)}\n\n"


def collect_knowledge_from_projects(db: Session, project_ids: List[int]) -> List[KnowledgeChunk]:
    """í”„ë¡œì íŠ¸ì—ì„œ ì§€ì‹ ì²­í¬ ìˆ˜ì§‘"""
    chunks = []
    for project_id in project_ids:
        project = db.query(Project).filter(Project.id == project_id).first()
        if not project:
            continue
        documents = db.query(Document).filter(Document.project_id == project_id).all()
        for doc in documents:
            doc_chunks = db.query(KnowledgeChunk).filter(
                KnowledgeChunk.document_id == doc.id,
                KnowledgeChunk.status == "approved"
            ).all()
            chunks.extend(doc_chunks)
    return chunks


def collect_knowledge_from_labels(db: Session, label_names: List[str]) -> List[KnowledgeChunk]:
    """ë¼ë²¨ì—ì„œ ì§€ì‹ ìˆ˜ì§‘"""
    chunks = []
    labels = db.query(Label).filter(Label.name.in_(label_names)).all()
    for label in labels:
        knowledge_labels = db.query(KnowledgeLabel).filter(KnowledgeLabel.label_id == label.id).all()
        for kl in knowledge_labels:
            chunk = db.query(KnowledgeChunk).filter(
                KnowledgeChunk.id == kl.chunk_id,
                KnowledgeChunk.status == "approved"
            ).first()
            if chunk:
                chunks.append(chunk)
    return chunks


def collect_knowledge_from_label_ids(db: Session, label_ids: List[int]) -> List[KnowledgeChunk]:
    """ë¼ë²¨ IDë¡œ ì§€ì‹ ìˆ˜ì§‘"""
    chunks = []
    knowledge_labels = db.query(KnowledgeLabel).filter(
        KnowledgeLabel.label_id.in_(label_ids),
        KnowledgeLabel.status == "confirmed"
    ).all()
    chunk_ids = {kl.chunk_id for kl in knowledge_labels}
    if chunk_ids:
        chunks = db.query(KnowledgeChunk).filter(
            KnowledgeChunk.id.in_(chunk_ids),
            KnowledgeChunk.status == "approved"
        ).all()
    return chunks


def trace_relations(db: Session, chunks: List[KnowledgeChunk], depth: int = 2) -> List[KnowledgeChunk]:
    """ê´€ê³„ë¥¼ ë”°ë¼ ì§€ì‹ ì²­í¬ ì¶”ì """
    all_chunks = {chunk.id: chunk for chunk in chunks}
    current_chunk_ids = [chunk.id for chunk in chunks]

    for _ in range(depth):
        if not current_chunk_ids:
            break
        relations = db.query(KnowledgeRelation).filter(
            (
                (KnowledgeRelation.source_chunk_id.in_(current_chunk_ids)) |
                (KnowledgeRelation.target_chunk_id.in_(current_chunk_ids))
            ),
            KnowledgeRelation.confirmed == "true"
        ).all()

        related_chunk_ids = set()
        for rel in relations:
            if rel.source_chunk_id in current_chunk_ids:
                related_chunk_ids.add(rel.target_chunk_id)
            if rel.target_chunk_id in current_chunk_ids:
                related_chunk_ids.add(rel.source_chunk_id)

        related_chunk_ids = related_chunk_ids - set(all_chunks.keys())
        if not related_chunk_ids:
            break

        next_chunks = db.query(KnowledgeChunk).filter(
            KnowledgeChunk.id.in_(related_chunk_ids),
            KnowledgeChunk.status == "approved"
        ).all()

        for chunk in next_chunks:
            all_chunks[chunk.id] = chunk
        current_chunk_ids = [chunk.id for chunk in next_chunks]

    return list(all_chunks.values())


async def _async_stream_tokens(sync_gen):
    """ë™ê¸° ì œë„ˆë ˆì´í„°ë¥¼ ë¹„ë™ê¸°ë¡œ ë³€í™˜ (executorì—ì„œ next() í˜¸ì¶œ) â€” Phase 10-4-1."""
    loop = asyncio.get_event_loop()
    it = iter(sync_gen)
    while True:
        try:
            token = await loop.run_in_executor(None, next, it)
            yield token
        except StopIteration:
            break


async def execute_reasoning_with_progress(
    task_id: str,
    request: ReasonStreamRequest,
    db: Session
) -> AsyncGenerator[str, None]:
    """ì§„í–‰ ìƒíƒœë¥¼ í¬í•¨í•œ Reasoning ì‹¤í–‰ (ì œë„ˆë ˆì´í„°)"""
    start_time = time.time()
    reasoning_steps = []

    # íƒœìŠ¤í¬ ë“±ë¡
    active_tasks[task_id] = {
        "status": "running",
        "started_at": start_time,
        "cancelled": False
    }

    try:
        # Stage 1: ì§ˆë¬¸ ë¶„ì„
        yield format_sse_event("progress", {
            "task_id": task_id,
            "stage": 1,
            "total_stages": 5,
            "message": "ì§ˆë¬¸ ë¶„ì„ ì¤‘...",
            "percent": 10,
            "elapsed": round(time.time() - start_time, 1)
        })

        # ì·¨ì†Œ í™•ì¸
        if active_tasks.get(task_id, {}).get("cancelled"):
            yield format_sse_event("cancelled", {"task_id": task_id, "message": "ì‚¬ìš©ìì— ì˜í•´ ì·¨ì†Œë¨"})
            return

        reasoning_steps.append("ì…ë ¥ íŒŒì‹± ì¤‘...")
        project_ids = request.inputs.get("projects", [])
        label_names = request.inputs.get("labels", [])
        filter_label_ids = []

        if request.filters:
            if request.filters.category_label_ids:
                filter_label_ids.extend(request.filters.category_label_ids)
            if request.filters.keyword_group_ids:
                filter_label_ids.extend(request.filters.keyword_group_ids)
            if request.filters.keyword_ids:
                filter_label_ids.extend(request.filters.keyword_ids)
            if request.filters.project_ids:
                project_ids = list(set(project_ids + request.filters.project_ids))

        question = (request.question or "").strip()
        await asyncio.sleep(0.1)  # UI ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ ì§§ì€ ëŒ€ê¸°

        # Stage 2: ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        yield format_sse_event("progress", {
            "task_id": task_id,
            "stage": 2,
            "total_stages": 5,
            "message": "ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...",
            "percent": 30,
            "elapsed": round(time.time() - start_time, 1)
        })

        if active_tasks.get(task_id, {}).get("cancelled"):
            yield format_sse_event("cancelled", {"task_id": task_id, "message": "ì‚¬ìš©ìì— ì˜í•´ ì·¨ì†Œë¨"})
            return

        chunks = []
        if question:
            reasoning_steps.append("ì§ˆë¬¸ ê¸°ë°˜ ì˜ë¯¸ ê²€ìƒ‰ ì¤‘...")
            search_service = get_search_service()
            search_results = search_service.search_simple(question.strip(), top_k=20, use_cache=False)
            seen = set()
            for result in search_results:
                qdrant_id = result.get("document_id")
                chunk = db.query(KnowledgeChunk).filter(
                    KnowledgeChunk.qdrant_point_id == str(qdrant_id),
                    KnowledgeChunk.status == "approved",
                ).first()
                if chunk and chunk.id not in seen:
                    seen.add(chunk.id)
                    chunks.append(chunk)
            reasoning_steps.append(f"ì˜ë¯¸ ê²€ìƒ‰ìœ¼ë¡œ {len(chunks)}ê°œ ì²­í¬ ìˆ˜ì§‘")

        # ë³´ì¡° í•„í„° ì ìš©
        if project_ids:
            project_chunks = collect_knowledge_from_projects(db, project_ids)
            seen = {c.id for c in chunks}
            for c in project_chunks:
                if c.id not in seen:
                    seen.add(c.id)
                    chunks.append(c)
            reasoning_steps.append(f"í”„ë¡œì íŠ¸ì—ì„œ {len(project_chunks)}ê°œ ì²­í¬ ìˆ˜ì§‘")

        if label_names:
            label_chunks = collect_knowledge_from_labels(db, label_names)
            seen = {c.id for c in chunks}
            for c in label_chunks:
                if c.id not in seen:
                    seen.add(c.id)
                    chunks.append(c)
            reasoning_steps.append(f"ë¼ë²¨ì—ì„œ {len(label_chunks)}ê°œ ì²­í¬ ìˆ˜ì§‘")

        if filter_label_ids:
            filter_chunks = collect_knowledge_from_label_ids(db, filter_label_ids)
            seen = {c.id for c in chunks}
            for c in filter_chunks:
                if c.id not in seen:
                    seen.add(c.id)
                    chunks.append(c)
            reasoning_steps.append(f"í‚¤ì›Œë“œ í•„í„°ì—ì„œ {len(filter_chunks)}ê°œ ì²­í¬ ìˆ˜ì§‘")

        # ì§ˆë¬¸ ì—†ì´ í•„í„°ë„ ì—†ì„ ë•Œ í´ë°±
        if not chunks and not question:
            fallback = db.query(KnowledgeChunk).filter(
                KnowledgeChunk.status == "approved"
            ).order_by(KnowledgeChunk.id.desc()).limit(100).all()
            if fallback:
                chunks = fallback
                reasoning_steps.append(f"í•„í„° ì—†ìŒ â†’ ìŠ¹ì¸ëœ ì „ì²´ ì²­í¬ {len(fallback)}ê°œ ì‚¬ìš©")

        await asyncio.sleep(0.1)

        # Stage 3: ì—°ê´€ ì§€ì‹ í™•ì¥
        yield format_sse_event("progress", {
            "task_id": task_id,
            "stage": 3,
            "total_stages": 5,
            "message": "ì—°ê´€ ì§€ì‹ í™•ì¥ ì¤‘...",
            "percent": 50,
            "elapsed": round(time.time() - start_time, 1)
        })

        if active_tasks.get(task_id, {}).get("cancelled"):
            yield format_sse_event("cancelled", {"task_id": task_id, "message": "ì‚¬ìš©ìì— ì˜í•´ ì·¨ì†Œë¨"})
            return

        reasoning_steps.append("ê´€ê³„ ì¶”ì  ì¤‘...")
        all_chunks = trace_relations(db, chunks, depth=2)
        reasoning_steps.append(f"ê´€ê³„ë¥¼ í†µí•´ {len(all_chunks) - len(chunks)}ê°œ ì¶”ê°€ ì²­í¬ ë°œê²¬")

        await asyncio.sleep(0.1)

        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        chunks_to_process = all_chunks[:20]
        chunk_ids = [c.id for c in chunks_to_process]

        document_ids = list(set([chunk.document_id for chunk in chunks_to_process]))
        documents = {doc.id: doc for doc in db.query(Document).filter(Document.id.in_(document_ids)).all()}

        project_ids_list = list(set([doc.project_id for doc in documents.values() if doc.project_id]))
        projects = {proj.id: proj for proj in db.query(Project).filter(Project.id.in_(project_ids_list)).all()} if project_ids_list else {}

        chunk_labels: Dict[int, List[str]] = {cid: [] for cid in chunk_ids}
        if chunk_ids:
            knowledge_labels = (
                db.query(KnowledgeLabel.chunk_id, Label.name)
                .join(Label, KnowledgeLabel.label_id == Label.id)
                .filter(
                    KnowledgeLabel.chunk_id.in_(chunk_ids),
                    KnowledgeLabel.status == "confirmed",
                )
                .all()
            )
            for cid, name in knowledge_labels:
                if name and cid in chunk_labels:
                    chunk_labels[cid].append(name)

        context_chunks = []
        for chunk in chunks_to_process:
            doc = documents.get(chunk.document_id)
            project = projects.get(doc.project_id) if doc and doc.project_id else None
            context_chunks.append({
                "id": chunk.id,
                "content": chunk.content[:200] + "..." if len(chunk.content) > 200 else chunk.content,
                "document": doc.file_name if doc else None,
                "project": project.name if project else None,
                "project_id": doc.project_id if doc else None,
                "labels": chunk_labels.get(chunk.id) or [],
            })

        # ê´€ê³„ ì •ë³´ ìˆ˜ì§‘
        relations = []
        if chunks[:10]:
            chunk_ids_for_rel = [chunk.id for chunk in chunks[:10]]
            all_relations = db.query(KnowledgeRelation).filter(
                KnowledgeRelation.source_chunk_id.in_(chunk_ids_for_rel)
            ).all()
            target_chunk_ids = list(set([rel.target_chunk_id for rel in all_relations]))
            target_chunks = {
                chunk.id: chunk
                for chunk in db.query(KnowledgeChunk).filter(KnowledgeChunk.id.in_(target_chunk_ids)).all()
            }
            chunk_dict = {chunk.id: chunk for chunk in chunks[:10]}
            for rel in all_relations:
                source_chunk = chunk_dict.get(rel.source_chunk_id)
                target_chunk = target_chunks.get(rel.target_chunk_id)
                if source_chunk and target_chunk:
                    relations.append({
                        "type": rel.relation_type,
                        "source": source_chunk.content[:50],
                        "target": target_chunk.content[:50],
                        "description": rel.description
                    })

        # Stage 4: AI ì¶”ë¡ 
        yield format_sse_event("progress", {
            "task_id": task_id,
            "stage": 4,
            "total_stages": 5,
            "message": "AI ì¶”ë¡  ì¤‘...",
            "percent": 70,
            "elapsed": round(time.time() - start_time, 1)
        })

        if active_tasks.get(task_id, {}).get("cancelled"):
            yield format_sse_event("cancelled", {"task_id": task_id, "message": "ì‚¬ìš©ìì— ì˜í•´ ì·¨ì†Œë¨"})
            return

        reasoning_steps.append("Reasoning ì‹¤í–‰ ì¤‘...")
        dynamic_svc = get_dynamic_reasoning_service()

        # Phase 10-4-1: í† í° ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë° ì‹œë„ â†’ ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ non-streaming í´ë°±
        answer_parts = []
        try:
            async for token in _async_stream_tokens(
                dynamic_svc.generate_reasoning_stream(
                    request.question, context_chunks, request.mode,
                    max_tokens=500, model=request.model
                )
            ):
                if active_tasks.get(task_id, {}).get("cancelled"):
                    yield format_sse_event("cancelled", {"task_id": task_id, "message": "ì‚¬ìš©ìì— ì˜í•´ ì·¨ì†Œë¨"})
                    return
                answer_parts.append(token)
                yield format_sse_event("answer_token", {"task_id": task_id, "token": token})
        except Exception as e:
            logger.debug("Streaming fallback triggered: %s", e)

        if answer_parts:
            answer = dynamic_svc._postprocess_reasoning("".join(answer_parts))
        else:
            # ìŠ¤íŠ¸ë¦¬ë° ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ non-streaming í´ë°±
            answer = dynamic_svc.generate_reasoning(
                request.question, context_chunks, request.mode, max_tokens=500, model=request.model
            )

        if answer is None:
            # í…œí”Œë¦¿ í´ë°±
            mode = request.mode
            if mode == "design_explain":
                answer = f"ğŸ“ ì„¤ê³„/ë°°ê²½ ì„¤ëª…\n\nìˆ˜ì§‘ëœ {len(all_chunks)}ê°œ ì§€ì‹ ì¡°ê°ì„ ê¸°ë°˜ìœ¼ë¡œ ì„¤ê³„ ë°°ê²½ê³¼ ë§¥ë½ì„ ì„¤ëª…í•©ë‹ˆë‹¤."
            elif mode == "risk_review":
                answer = f"âš ï¸ ë¦¬ìŠ¤í¬ ë¶„ì„\n\n{len(all_chunks)}ê°œ ê´€ë ¨ ì§€ì‹ì„ ë¶„ì„í•˜ì—¬ ì ì¬ì  ë¦¬ìŠ¤í¬ë¥¼ ì‹ë³„í•©ë‹ˆë‹¤."
            elif mode == "next_steps":
                answer = f"ğŸš€ ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ\n\n{len(all_chunks)}ê°œ ê´€ë ¨ ì§€ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤."
            else:
                answer = f"ğŸ“œ íˆìŠ¤í† ë¦¬/ë§¥ë½ ì¶”ì \n\n{len(all_chunks)}ê°œ ì§€ì‹ì„ ì‹œê°„ì /ë…¼ë¦¬ì  ìˆœì„œë¡œ ì¶”ì í•©ë‹ˆë‹¤."

        reasoning_steps.append("Reasoning ì™„ë£Œ")

        # Stage 5: ì¶”ì²œ ì •ë³´ ìƒì„±
        yield format_sse_event("progress", {
            "task_id": task_id,
            "stage": 5,
            "total_stages": 5,
            "message": "ì¶”ì²œ ì •ë³´ ìƒì„± ì¤‘...",
            "percent": 90,
            "elapsed": round(time.time() - start_time, 1)
        })

        if active_tasks.get(task_id, {}).get("cancelled"):
            yield format_sse_event("cancelled", {"task_id": task_id, "message": "ì‚¬ìš©ìì— ì˜í•´ ì·¨ì†Œë¨"})
            return

        recommendations = None
        try:
            rec_svc = get_recommendation_service(db)
            context_chunk_ids = [c.get("id") for c in context_chunks if c.get("id")]
            related_chunks = rec_svc.recommend_related_chunks(context_chunk_ids, limit=5) if context_chunk_ids else []
            combined_content = " ".join([(c.get("content") or "")[:300] for c in context_chunks])
            suggested_labels = rec_svc.recommend_labels(combined_content, limit=5) if combined_content.strip() else []
            sample_questions = rec_svc.generate_sample_questions(limit=3, model=request.model)
            explore_more = rec_svc.suggest_exploration(context_chunk_ids=context_chunk_ids, limit=5)
            recommendations = {
                "related_chunks": related_chunks,
                "suggested_labels": suggested_labels,
                "sample_questions": sample_questions,
                "explore_more": explore_more,
            }
        except Exception as e:
            logger.debug("recommendations build failed: %s", e)

        # ì™„ë£Œ
        elapsed_time = round(time.time() - start_time, 1)
        yield format_sse_event("progress", {
            "task_id": task_id,
            "stage": 5,
            "total_stages": 5,
            "message": "ì™„ë£Œ!",
            "percent": 100,
            "elapsed": elapsed_time
        })

        # ìµœì¢… ê²°ê³¼ ì „ì†¡
        result = {
            "task_id": task_id,
            "answer": answer,
            "context_chunks": context_chunks,
            "relations": relations,
            "reasoning_steps": reasoning_steps,
            "recommendations": recommendations,
            "elapsed_time": elapsed_time
        }
        yield format_sse_event("result", result)
        yield format_sse_event("done", {"task_id": task_id})

    except Exception as e:
        logger.error("Reasoning error: %s", e)
        yield format_sse_event("error", {
            "task_id": task_id,
            "message": str(e)
        })
    finally:
        # íƒœìŠ¤í¬ ì •ë¦¬
        if task_id in active_tasks:
            del active_tasks[task_id]


@router.post("/stream")
async def reason_stream(request: ReasonStreamRequest, db: Session = Depends(get_db)):
    """
    Reasoning ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰ (SSE)

    ì§„í–‰ ìƒíƒœë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì „ì†¡í•˜ë©°, ì·¨ì†Œ ê¸°ëŠ¥ì„ ì§€ì›í•©ë‹ˆë‹¤.

    ì´ë²¤íŠ¸ íƒ€ì…:
    - progress: ì§„í–‰ ìƒíƒœ ì—…ë°ì´íŠ¸
    - result: ìµœì¢… ê²°ê³¼
    - cancelled: ì·¨ì†Œë¨
    - error: ì˜¤ë¥˜ ë°œìƒ
    - done: ì™„ë£Œ
    """
    task_id = str(uuid.uuid4())

    return StreamingResponse(
        execute_reasoning_with_progress(task_id, request, db),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",
            "X-Task-ID": task_id
        }
    )


@router.post("/{task_id}/cancel")
async def cancel_reasoning(task_id: str):
    """
    ì§„í–‰ ì¤‘ì¸ Reasoning ì‘ì—… ì·¨ì†Œ (Phase 10-1-2)

    Args:
        task_id: ì·¨ì†Œí•  íƒœìŠ¤í¬ ID

    Returns:
        ì·¨ì†Œ ê²°ê³¼
    """
    if task_id not in active_tasks:
        raise HTTPException(status_code=404, detail="íƒœìŠ¤í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    if active_tasks[task_id].get("cancelled"):
        return {"message": "ì´ë¯¸ ì·¨ì†Œëœ íƒœìŠ¤í¬ì…ë‹ˆë‹¤.", "task_id": task_id}

    active_tasks[task_id]["cancelled"] = True
    return {"message": "ì·¨ì†Œ ìš”ì²­ë¨", "task_id": task_id}


@router.get("/tasks")
async def list_active_tasks():
    """
    ì§„í–‰ ì¤‘ì¸ íƒœìŠ¤í¬ ëª©ë¡ ì¡°íšŒ

    Returns:
        í™œì„± íƒœìŠ¤í¬ ëª©ë¡
    """
    return {
        "tasks": [
            {
                "task_id": task_id,
                "status": info.get("status"),
                "started_at": info.get("started_at"),
                "cancelled": info.get("cancelled", False)
            }
            for task_id, info in active_tasks.items()
        ],
        "count": len(active_tasks)
    }


@router.get("/eta")
async def get_estimated_time(mode: str = "design_explain"):
    """
    ì˜ˆìƒ ì†Œìš” ì‹œê°„ ì¡°íšŒ (Phase 10-1-3)

    ëª¨ë“œë³„ ì˜ˆìƒ ì†Œìš” ì‹œê°„ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    í˜„ì¬ëŠ” íœ´ë¦¬ìŠ¤í‹± ê¸°ë°˜ ê³ ì •ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

    Args:
        mode: Reasoning ëª¨ë“œ

    Returns:
        ì˜ˆìƒ ì†Œìš” ì‹œê°„ (ì´ˆ)
    """
    # ëª¨ë“œë³„ ì˜ˆìƒ ì‹œê°„ (íœ´ë¦¬ìŠ¤í‹±)
    eta_map = {
        "design_explain": {"min": 20, "max": 45, "typical": 30},
        "risk_review": {"min": 25, "max": 50, "typical": 35},
        "next_steps": {"min": 20, "max": 40, "typical": 28},
        "history_trace": {"min": 25, "max": 55, "typical": 38},
    }

    eta = eta_map.get(mode, eta_map["design_explain"])

    return {
        "mode": mode,
        "estimated_seconds": eta,
        "display_text": f"ì•½ {eta['min']}ì´ˆ ~ {eta['max']}ì´ˆ",
        "typical_text": f"ì¼ë°˜ì ìœ¼ë¡œ ì•½ {eta['typical']}ì´ˆ"
    }


# ---------- 11-5-3: ETA í”¼ë“œë°± (ì‹¤ì œ ì†Œìš” ì‹œê°„ ë°˜ì˜ìš©) ----------

class ETAFeedbackBody(BaseModel):
    mode: Optional[str] = "design_explain"
    actual_seconds: int


@router.post("/eta/feedback")
async def eta_feedback(body: ETAFeedbackBody):
    """
    11-5-3: ì‹¤ì œ ì†Œìš” ì‹œê°„ í”¼ë“œë°±.
    í–¥í›„ ETA ì˜ˆì¸¡ ë³´ì •ì— í™œìš©í•  ìˆ˜ ìˆë„ë¡ ë¡œê¹…í•©ë‹ˆë‹¤.
    """
    logger.info(
        "ETA feedback: mode=%s actual_seconds=%s",
        body.mode or "design_explain",
        body.actual_seconds,
    )
    return {"ok": True, "mode": body.mode, "actual_seconds": body.actual_seconds}
